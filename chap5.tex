\chapter{结语}

\section{结论}

本文在第\ref{section:HearthstoneAI}章介绍了炉石传说的基本规则，并介绍了为了炉石传说开发基于蒙特卡洛搜索的智能体的基本方法。

第\ref{section:experimentalResults}章构建了四个不同的炉石传说智能体并使其进行两两对弈。最终得知，本文使用的规则智能体比普通的随机智能体有强得多的决策强度。
完全不包含先验知识的随机模拟的蒙特卡洛智能体能够轻易击败最弱的随机智能体，与拥有大量先验知识的规则智能体对弈时亦能拥有不错的表现。
基于规则模拟的蒙特卡洛智能体加入了规则智能体所拥有的先验知识，在决策强度上有了一定的提升，能比随机蒙特卡洛智能体更快趋于稳定，稳定后的胜率也比随机蒙特卡洛智能体稍高。
这意味着，蒙特卡洛搜索的加入能够提高智能体的决策强度，规则智能体的先验知识的加入同样能够提高智能体的决策强度，而先验知识的加入与蒙特卡洛搜索算法之间并不冲突。
蒙特卡洛搜索意味着无启发知识的搜索型智能体，规则智能体则意味着依赖启发知识的启发型智能体。
它们代表着截然不同的人工智能研究方向，而两者相结合所带来的成功意味深远。
不幸的是，先验知识的加入导致规则蒙特卡洛智能体的表现发生了偏差：它能比随机蒙特卡洛智能体更好地应对规则智能体，但在面对其他类型的对手时的表现却有所下降。

除此之外，实验部分还验证了迭代次数对蒙特卡洛智能体决策强度的影响。可见，对于每回合可进行的操作序列的总数普遍维持在50以内的炉石传说而言，
500次的蒙特卡洛迭代已足以让蒙特卡洛搜索算法近似求得各个操作的期望收益，更多的迭代已不能继续得到更好的结果。
考虑到500次的迭代对现代计算机而言只需要1秒的处理时间，蒙特卡洛人工智能在性能上也是可以接受的。

\section{未来的工作方向}

蒙特卡洛搜索固然能带来智能体决策强度的提高，但先验知识的加入对蒙特卡洛智能体的提升却是显而易见的。
炉石传说人工智能仍然可以通过各种方式加入更多的先验知识：无论是基于规则的智能体，还是利用学习算法使得智能体拥有学习能力，
本文的实验结果都确保了它们的加入能够更好地模拟对手的行为，为智能体的决策强度带来提高。
在炉石传说这样的不完全信息游戏中，对手行为预测是十分重要的。而要对对手进行预测，加入启发知识并不是唯一的方法。

前文提到了蒙特卡洛搜索的延伸算法，蒙特卡洛树搜索。蒙特卡洛树搜索与蒙特卡洛搜索类似，但其同时考虑了对手即将可能进行的操作，将其构造成了一个博弈树，
并使用UCT算法来选择模拟的叶子节点。考虑到炉石传说的隐藏信息太多，直接使用蒙特卡洛树搜索构造博弈树将面临比围棋大得多的分支系数，因此本文并未使用蒙特卡洛树搜索。
但毋庸置疑，蒙特卡洛树搜索也是十分有价值的研究方向。
